{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Το dataset 'Severe Weather Data Inventory (SWDI)' του National Oceanic Atmospheric Administration (NOAA) ειναι μια βάση δεδομένων για καιρικά φαινόμενα με έντονη δριμύτητα. Εκεί καταγράφονται πληροφορίες για την εμφάνιση έντονων καιρικών φαινομένων από το 1950 μέχρι σήμερα. Οι πληροφορίες σε γενικές γραμμές αφορούν το είδος του φαινομένου (πχ τυφώνας, πλημμύρα), την τοποθεσία και τον αντίκτυπο σε υλικές ζημιές και στους ανθρώπους. Θα το δούμε πιο λεπτομερώς στη συνέχεια."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εισάγουμε τις βιβλιοθήκες και τα modules που θα χρειαστούμε."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Διαβάζουμε το csv αρχείο του dataset σε ένα pandas' DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1639004 entries, 0 to 1639003\n",
      "Data columns (total 34 columns):\n",
      "Unnamed: 0            1639004 non-null int64\n",
      "episode_id            1406765 non-null float64\n",
      "event_id              1639004 non-null int64\n",
      "state                 1639003 non-null object\n",
      "state_fips_code       1639003 non-null float64\n",
      "event_type            1639004 non-null object\n",
      "cz_type               1639004 non-null object\n",
      "cz_fips_code          1639004 non-null int64\n",
      "cz_name               1637447 non-null object\n",
      "wfo                   1513431 non-null object\n",
      "event_begin_time      1639004 non-null object\n",
      "event_timezone        1639004 non-null object\n",
      "event_end_time        1639004 non-null object\n",
      "injuries_direct       1639004 non-null int64\n",
      "injuries_indirect     1639004 non-null int64\n",
      "deaths_direct         1639004 non-null int64\n",
      "deaths_indirect       1639004 non-null int64\n",
      "damage_property       1078595 non-null float64\n",
      "damage_crops          961257 non-null float64\n",
      "source                1293139 non-null object\n",
      "magnitude             954010 non-null float64\n",
      "magnitude_type        387982 non-null object\n",
      "flood_cause           83916 non-null object\n",
      "tor_f_scale           69660 non-null object\n",
      "tor_length            373913 non-null float64\n",
      "tor_width             426306 non-null float64\n",
      "tor_other_wfo         2250 non-null object\n",
      "location_index        1057787 non-null float64\n",
      "event_range           636243 non-null float64\n",
      "event_azimuth         597824 non-null object\n",
      "reference_location    841397 non-null object\n",
      "event_latitude        771703 non-null float64\n",
      "event_longitude       771703 non-null float64\n",
      "event_point           771703 non-null object\n",
      "dtypes: float64(11), int64(7), object(16)\n",
      "memory usage: 425.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Από τις πληροφορίες του dataset, βλέπουμε ότι έχουμε 1639004 entries και 34 columns , που αντιστοιχούν στις εξής πληροφορίες:\n",
    "\n",
    "0. index\n",
    "\n",
    "\n",
    "1. episode_id:           ID assigned by NWS to denote the storm episode; links the event details file with the information within location file.\n",
    "\n",
    "\n",
    "2. event_id:             ID assigned by NWS to note a single, small part that goes into a specific storm episode; links the storm episode between the three files downloaded from SPC’s website.\n",
    "\n",
    "\n",
    "3. state:                The full text state name where the event occurred.\n",
    "\n",
    "\n",
    "4. state_fips_code:      Unique FIPS code identifier assigned to each state. State names and their corresponding FIPS codes are available as a BigQuery Public Dataset: bigquery-public-data.census_fips_codes.states_2016  The geographic polygons that define the perimeter of each state are available as a BigQuery Public Dataset: bigquery-public-data.geo_us_boundaries.us_states.\n",
    "\n",
    "\n",
    "5. event_type:           The only events permitted in Storm Data are listed in Table 1 of Section 2.1.1 of NWS Directive 10-1605 at http://www.nws.noaa.gov/directives/sym/pd01016005curr.pdf. The chosen event type is the one that most accurately describes the meteorological event leading to fatalities, injuries, damage, etc. However, significant events, such as tornadoes, having no impact or causing no damage, are also included in Storm Data.\n",
    "\n",
    "\n",
    "6. cz_type:              Indicates whether the event happened in   - C: County/Parish  - Z: NWS zone  - M: Marine\n",
    "\n",
    "\n",
    "7. cz_fips_code:         Unique FIPS code identifier assigned to each county.   State names and their corresponding FIPS codes are available as a BigQuery Public Dataset: bigquery-public-data.census_fips_codes.counties_2016  The geographic polygons that define the perimeter of each state are available as a BigQuery Public Dataset: bigquery-public-data.geo_us_boundaries.us_counties.\n",
    "\n",
    "\n",
    "8. cz_name:              (County/Parish, Zone or Marine Name assigned to the county FIPS number or NWS Forecast Zone  NWS Forecast Zones are available as a BigQuery Public Dataset: bigquery-public-data.noaa_historic_severe_storms.nws_forecast_zones.\n",
    "\n",
    "\n",
    "9. wfo:                  National Weather Service Forecast Office’s area of responsibility (County Warning Area) in which the event occurred.\n",
    "\n",
    "\n",
    "10. event_begin_time:     The date and time that the event began. Note that episodes and events may have different start and end times if multiple events occured in the same episode.\n",
    "\n",
    "\n",
    "11. event_timezone:       The time zone in which the event_begin_time and the event_end_time is recorded.\n",
    "\n",
    "\n",
    "12. event_end_time:       The date and time that the event ended. Note that episodes and events may have different start and end times if multiple events occured in the same episode.\n",
    "\n",
    "\n",
    "13. injuries_direct:      The number of injuries directly related to the weather event.\n",
    "\n",
    "\n",
    "14. injuries_indirect:    The number of injuries indirectly related to the weather event.\n",
    "\n",
    "\n",
    "15. deaths_direct:        The number of deaths directly related to the weather event.\n",
    "\n",
    "\n",
    "16. deaths_indirect:      The number of deaths indirectly related to the weather event.\n",
    "\n",
    "\n",
    "17. damage_property:      The estimated amount of damage to property incurred by the weather event, in USD at the time of the event. Values are not adjusted for inflation  Note: Values listed as 0 do not necessarily mean that no property damage occurred as a result of the event.\n",
    "\n",
    "\n",
    "18. damage_crops:         The estimated amount of damage to crops incurred by the weather event, in USD at the time of the storm. Values are not adjusted for inflation  Note: Values listed as 0 do not necessarily mean that no property damage occurred as a result of the event.\n",
    "\n",
    "\n",
    "19. source:               Source reporting the weather event  Note: This can be any entry. Values are not restricted to specific categories.\n",
    "\n",
    "\n",
    "20. magnitude:            Measured extent of the magnitude type. This is only used for wind speeds and hail size. Wind speeds are in MPH; Hail sizes are in inches.\n",
    "\n",
    "\n",
    "21. magnitude_type:       Differentiates between the type of mangitude measured. - EG = Wind Estimated Gust  - ES = Estimated Sustained Wind  - MS = Measured Sustained Wind  - MG = Measured Wind Gust  No magnitude type is included for hail.\n",
    "\n",
    "\n",
    "22. flood_cause:          Reported or estimated cause of the flood.\n",
    "\n",
    "\n",
    "23. tor_f_scale:          Enhanced Fujita Scale describes the strength of the tornado based on the amount and type of damage caused by the tornado. The F-scale of damage will vary in the destruction area; therefore, the highest value of the F-scale is recorded for each event.    - EF0 – Light Damage (40 – 72 mph)   - EF1 – Moderate Damage (73 – 112 mph)   - EF2 – Significant damage (113 – 157 mph)   - EF3 – Severe Damage (158 – 206 mph)   - EF4 – Devastating Damage (207 – 260 mph)   - EF5 – Incredible Damage (261 – 318 mph).\n",
    "\n",
    "\n",
    "24. tor_length:           Length of the tornado or tornado segment while on the ground (minimal of tenths of miles).\n",
    "\n",
    "\n",
    "25. tor_width:            Width of the tornado or tornado segment while on the ground (in feet).\n",
    "\n",
    "\n",
    "26. tor_other_wfo:        Indicates the continuation of a tornado segment as it crossed from one National Weather Service Forecast Office to another. The subsequent WFO identifier is provided within this field..\n",
    "\n",
    "\n",
    "27. location_index:       Number assigned by NWS to specific locations within the same Storm event. Each event’s sequentially increasing location index number will have a corresponding lat/lon point.\n",
    "\n",
    "\n",
    "28. event_range:          A hydro-meteorological event will be referenced, minimally, to the nearest tenth of a mile, to the geographical center (not from the village/city boundaries or limits) of a particular village/city, airport, or inland lake, providing that the reference point is documented in the Storm Data software location database.\n",
    "\n",
    "\n",
    "29. event_azimuth:        16-point compass direction from a particular village/city, airport, or inland lake, providing that the reference point is documented in the Storm Data software location database of > 130,000 locations.\n",
    "\n",
    "\n",
    "30. reference_location:   Reference location of the center from which the range is calculated and the azimuth is determined.\n",
    "\n",
    "\n",
    "31. event_latitude:       The latitude where the event occurred (rounded to the hundredths in decimal degrees; includes an ‘-‘ if it’s S of the Equator).\n",
    "\n",
    "\n",
    "32. event_longitude:      The longitude where the event occurred (rounded to the hundredths in decimal degrees; includes an ‘-‘ if it’s W of the Prime Meridian).\n",
    "\n",
    "\n",
    "33. event_point:          Geographic representation of the event_longitude and latitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αφαιρούμε τις παρακάτω στήλες, καθώς δε μας χρειάζονται στην ανάλυσή μας."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:   \n",
    "    del df['source']\n",
    "    del df['flood_cause']\n",
    "    #del df['tor_length']\n",
    "    #del df['tor_width']\n",
    "    del df['tor_other_wfo']\n",
    "    del df['location_index']\n",
    "    del df['event_azimuth']\n",
    "    del df['event_range']\n",
    "    del df['reference_location']\n",
    "    del df['cz_fips_code']\n",
    "    del df['state_fips_code']\n",
    "    del df['cz_name']\n",
    "    del df['wfo']\n",
    "    del df['event_timezone']\n",
    "    \n",
    "    del df['Unnamed: 0']\n",
    "    # del df['episode_id']\n",
    "    # del df['event_id']\n",
    "    \n",
    "    del df['event_point']\n",
    "    # del df['magnitude_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ενοποιήσαμε ορισμένες κατηγορίες φαινομένων και δημιουργήαμε νέες στήλες, όπως φαίνεται παρακάτω:\n",
    "\n",
    "Generating new features:\n",
    "\n",
    "- damage - > damage properties + damage crops\n",
    "- injuries -> indirect + direct\n",
    "- deaths   -> indirect + direct\n",
    "- total_human_damage - > injuries + deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ενώνουμε τα deaths και τα injuries (direct - indirect) και μετά σβήνουμε τις άλλες (χωριστές) στήλες\n",
    "df['deaths'] = df['deaths_direct'] + df['deaths_indirect']\n",
    "df['injuries'] = df['injuries_direct'] + df['injuries_indirect']\n",
    "# Δημιουργούμε μια καινούρια στήλη η οποία περιέχει το άθροισμα των deaths και των injuries\n",
    "df['total_human_damage'] = df['injuries'] + df['deaths']\n",
    "del df['injuries_direct']\n",
    "del df['injuries_indirect']\n",
    "del df['deaths_direct']\n",
    "del df['deaths_indirect']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εκτυπώνουμε τις μοναδικές τιμές των event types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique event types:  77\n",
      "['Hail' 'Thunderstorm Wind' 'Tornado' 'THUNDERSTORM WINDS/ FLOOD'\n",
      " 'THUNDERSTORM WINDS FUNNEL CLOU' 'HAIL FLOODING'\n",
      " 'THUNDERSTORM WINDS/FLASH FLOOD' 'THUNDERSTORM WINDS HEAVY RAIN'\n",
      " 'THUNDERSTORM WINDS/HEAVY RAIN' 'THUNDERSTORM WINDS LIGHTNING'\n",
      " 'TORNADO/WATERSPOUT' 'THUNDERSTORM WIND/ TREE' 'THUNDERSTORM WIND/ TREES'\n",
      " 'winter storm' 'winter weather' 'heavy snow' 'cold/wind chill'\n",
      " 'high wind' 'strong wind' 'wildfire' 'thunderstorm wind' 'blizzard'\n",
      " 'hail' 'tornado' 'flash flood' 'funnel cloud' 'heavy rain' 'heat'\n",
      " 'lightning' 'dust devil' 'flood' 'extreme cold/wind chill' 'drought'\n",
      " 'avalanche' 'coastal flood' 'high surf' 'marine thunderstorm wind'\n",
      " 'marine strong wind' 'waterspout' 'lake-effect snow' 'ice storm'\n",
      " 'frost/freeze' 'excessive heat' 'marine hail' 'tropical storm'\n",
      " 'marine tropical storm' 'marine high wind' 'sleet' 'rip current'\n",
      " 'tropical depression' 'storm surge/tide' 'sneakerwave' 'hurricane'\n",
      " 'marine hurricane/typhoon' 'dense fog' 'lakeshore flood' 'freezing fog'\n",
      " 'dust storm' 'debris flow' 'astronomical low tide'\n",
      " 'marine tropical depression' 'dense smoke' 'seiche' 'volcanic ash'\n",
      " 'hurricane (typhoon)' 'landslide' 'volcanic ashfall'\n",
      " 'tornadoes, tstm wind, hail' 'marine dense fog' 'hail/icy roads'\n",
      " 'thunderstorm winds/flooding' 'tsunami' 'other' 'high snow' 'heavy wind'\n",
      " 'northern lights' 'marine lightning']\n"
     ]
    }
   ],
   "source": [
    "# unique event types\n",
    "print('unique event types: ', len(df['event_type'].unique()))\n",
    "print(df['event_type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρατηρηρούμε ότι μερικά από τα event types, όπως το hail που ήταν γραμμένο ως 'hail' αλλά και 'Hail', οπότε το διορθώσαμε μετατρέποντάς τα όλα lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "df['event_type'] = df['event_type'].str.lower()\n",
    "print(len(df['event_type'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ωστόσο, παρά τη διόρθωση αυτή, τα event types είναι πολλά. Επομένως, αποφασίσαμε αρχικά να συγχωνεύσουμε κάποια τα οποία μοιάζουν πολύ, όπως για παράδειγμα:\n",
    "\n",
    "\tthunderstorm_winds heavy rain και thunderstorm_winds / heavy rain → thunderstorm wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hail' 'thunderstorm wind' 'tornado' 'winter storm' 'winter weather'\n",
      " 'snow' 'cold/wind chill' 'wind' 'wildfire' 'flash flood' 'funnel cloud'\n",
      " 'heavy rain' 'drought' 'lightning' 'dust devil' 'flood' 'hurricane'\n",
      " 'ice storm' 'frost/freeze' 'excessive heat' 'tropical storm'\n",
      " 'marine tropical storm' 'marine high wind' 'sleet' 'rip current'\n",
      " 'tropical depression' 'storm surge/tide' 'sneakerwave' 'dense fog'\n",
      " 'freezing fog' 'storm' 'debris flow' 'astronomical low tide'\n",
      " 'marine tropical depression' 'dense smoke' 'seiche' 'volcanic ash'\n",
      " 'landslide' 'volcanic ashfall' 'marine dense fog' 'tsunami' 'other'\n",
      " 'northern lights' 'marine lightning']\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "# διορθώσεις ονομάτων στα event types\n",
    "storm_types_mapping = {\n",
    "'hail/icy roads': 'hail',\n",
    "'hail flooding': 'hail',\n",
    "'marine hail': 'hail',\n",
    "'hail' : 'hail',\n",
    "'thunderstorm winds funnel clou': 'thunderstorm wind',\n",
    "'thunderstorm winds/flash flood': 'thunderstorm wind',\n",
    "'thunderstorm winds heavy rain': 'thunderstorm wind',\n",
    "'thunderstorm winds/heavy rain': 'thunderstorm wind',\n",
    "'thunderstorm winds lightning': 'thunderstorm wind',\n",
    "'thunderstorm winds/flooding': 'thunderstorm wind',\n",
    "'thunderstorm winds/ flood': 'thunderstorm wind',\n",
    "'marine thunderstorm wind': 'thunderstorm wind',\n",
    "'thunderstorm wind/ trees': 'thunderstorm wind',\n",
    "'thunderstorm wind/ tree': 'thunderstorm wind',\n",
    "'thunderstorm wind': 'thunderstorm wind',\n",
    "# https://oceanservice.noaa.gov/facts/cyclone.html   typhoon = hurricane\n",
    "'hurricane (typhoon)': 'hurricane',\n",
    "'marine hurricane/typhoon': 'hurricane',\n",
    "'waterspout': 'hurricane',\n",
    "'hurricane': 'hurricane',\n",
    "'tornadoes, tstm wind, hail': 'tornado',\n",
    "'tornado/waterspout': 'tornado',\n",
    "'tornado': 'tornado',\n",
    "'flash flood': 'flash flood',\n",
    "'lakeshore flood': 'flood',\n",
    "'coastal flood': 'flood',\n",
    "'high surf': 'flood',\n",
    "'flood': 'flood',\n",
    "'drought': 'drought',\n",
    "'heat': 'drought',\n",
    "'cold/wind chill': 'cold/wind chill',\n",
    "'extreme cold/wind chill': 'wind',\n",
    "'marine strong wind': 'wind',\n",
    "'strong wind': 'wind',\n",
    "'heavy wind': 'wind',\n",
    "'high wind': 'wind',\n",
    "'lake-effect snow': 'snow',\n",
    "'heavy snow': 'snow',\n",
    "'avalanche': 'snow',\n",
    "'high snow': 'snow',\n",
    "'blizzard': 'snow',\n",
    "'wildfire': 'wildfire',\n",
    "'heavy rain': 'heavy rain',\n",
    "'storm surge/tide': 'storm surge/tide',\n",
    "'dust storm': 'storm',\n",
    "'tsunami': 'tsunami',\n",
    "'winter weather': 'winter weather',\n",
    "'winter storm': 'winter storm',\n",
    "'frost/freeze': 'frost/freeze',\n",
    "'marine tropical depression': 'marine tropical depression',\n",
    "'marine tropical storm': 'marine tropical storm',\n",
    "'astronomical low tide': 'astronomical low tide',\n",
    "'tropical depression': 'tropical depression',\n",
    "'marine high wind': 'marine high wind',\n",
    "'volcanic ashfall': 'volcanic ashfall',\n",
    "'marine dense fog': 'marine dense fog',\n",
    "'marine lightning': 'marine lightning',\n",
    "'northern lights': 'northern lights',\n",
    "'excessive heat': 'excessive heat',\n",
    "'tropical storm': 'tropical storm',\n",
    "'debris flow': 'debris flow',\n",
    "'dense smoke': 'dense smoke',\n",
    "'volcanic ash': 'volcanic ash',\n",
    "'freezing fog': 'freezing fog',\n",
    "'sneakerwave': 'sneakerwave',\n",
    "'rip current': 'rip current',\n",
    "'funnel cloud': 'funnel cloud',\n",
    "'landslide': 'landslide',\n",
    "'dust devil': 'dust devil',\n",
    "'ice storm': 'ice storm',\n",
    "'dense fog': 'dense fog',\n",
    "'lightning': 'lightning',\n",
    "'seiche': 'seiche',\n",
    "'sleet': 'sleet',\n",
    "'other': 'other'\n",
    "}\n",
    "\n",
    "def get_storm_type(k):\n",
    "    return storm_types_mapping[k]\n",
    "\n",
    "df.reset_index(drop=True)\n",
    "df1 = copy.deepcopy(df)\n",
    "df1['event_type'] = df1['event_type'].apply(get_storm_type)\n",
    "\n",
    "print(df1.event_type.unique())\n",
    "print(len(df1['event_type'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τα είδη των φαινομένων εξακολουθούν να είναι πολλά (42), επομένως μελετάμε τη συχνότητα εμφάνισης του κάθε φαινομένου στο dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thunderstorm wind             29.740318\n",
      "hail                          23.202018\n",
      "wind                           6.465939\n",
      "flash flood                    5.347943\n",
      "snow                           4.972044\n",
      "drought                        4.826285\n",
      "winter storm                   4.654229\n",
      "tornado                        4.370154\n",
      "flood                          4.209264\n",
      "winter weather                 3.656794\n",
      "heavy rain                     1.547769\n",
      "lightning                      1.068515\n",
      "cold/wind chill                0.872054\n",
      "dense fog                      0.821169\n",
      "frost/freeze                   0.726539\n",
      "ice storm                      0.713299\n",
      "funnel cloud                   0.537033\n",
      "excessive heat                 0.515740\n",
      "wildfire                       0.455093\n",
      "hurricane                      0.445331\n",
      "tropical storm                 0.321964\n",
      "rip current                    0.084258\n",
      "storm surge/tide               0.082245\n",
      "storm                          0.070226\n",
      "debris flow                    0.068639\n",
      "sleet                          0.047773\n",
      "astronomical low tide          0.033313\n",
      "marine high wind               0.027090\n",
      "freezing fog                   0.025076\n",
      "tropical depression            0.023551\n",
      "landslide                      0.022697\n",
      "dust devil                     0.014277\n",
      "marine tropical storm          0.008664\n",
      "dense smoke                    0.005003\n",
      "volcanic ash                   0.004881\n",
      "volcanic ashfall               0.004271\n",
      "seiche                         0.004027\n",
      "tsunami                        0.002013\n",
      "sneakerwave                    0.000976\n",
      "northern lights                0.000488\n",
      "marine dense fog               0.000488\n",
      "marine tropical depression     0.000427\n",
      "other                          0.000061\n",
      "marine lightning               0.000061\n",
      "Name: event_type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "temp = (df1['event_type'].value_counts() / len(df)) * 100\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αποφασίζουμε τελικά να αφαιρέσουμε αυτά που παρουσιάζουν τη πολύ μικρή συχνότητα εμφανίσεων. Συγκεκριμένα θα αφαιρέσουμε αυτά τα οποία έχουν ποσοστό εμφάνισης όλα αυτά τα χρόνια <0.01% επί του συνόλου."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event types we dont keep:\n",
      " ['marine tropical storm', 'dense smoke', 'volcanic ash', 'volcanic ashfall', 'seiche', 'tsunami', 'sneakerwave', 'northern lights', 'marine dense fog', 'marine tropical depression', 'other', 'marine lightning']\n",
      "\n",
      "Event types we keep:\n",
      " ['hail' 'thunderstorm wind' 'tornado' 'winter storm' 'winter weather'\n",
      " 'snow' 'cold/wind chill' 'wind' 'wildfire' 'flash flood' 'funnel cloud'\n",
      " 'heavy rain' 'drought' 'lightning' 'dust devil' 'flood' 'hurricane'\n",
      " 'ice storm' 'frost/freeze' 'excessive heat' 'tropical storm'\n",
      " 'marine high wind' 'sleet' 'rip current' 'tropical depression'\n",
      " 'storm surge/tide' 'dense fog' 'freezing fog' 'storm' 'debris flow'\n",
      " 'astronomical low tide' 'landslide']\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "temp = temp[temp < 0.01]\n",
    "event_types_we_dont_keep = []\n",
    "for i in temp.index:\n",
    "    event_types_we_dont_keep.append(i)\n",
    "print('Event types we dont keep:\\n', event_types_we_dont_keep)\n",
    "print(\"\")\n",
    "df1.reset_index(drop=True)\n",
    "df2 = df1[~df1['event_type'].isin(event_types_we_dont_keep)]\n",
    "print('Event types we keep:\\n',df2['event_type'].unique())\n",
    "\n",
    "print(len(df2['event_type'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για τα χαρακτηριστικά event_latitude , event_longitude, τα οποία αναφέρονται σε συντεταγμένες, κάνουμε την εξής επεξεργασία: εφόσον, οι περιοχές είναι πάντα στις ίδιες συντεταγμένες, πήραμε το μέσο όρο του long και του lat για κάθε state και αντικαθιστούμε τα nan values στις γεωγραφικές τιμές με αυτά."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_longitude</th>\n",
       "      <th>event_latitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>-86.794329</td>\n",
       "      <td>33.273120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>-148.691622</td>\n",
       "      <td>62.656039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American samoa</th>\n",
       "      <td>-170.606827</td>\n",
       "      <td>-9.855073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>-111.818135</td>\n",
       "      <td>33.593247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>-92.645165</td>\n",
       "      <td>34.977785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>-78.658510</td>\n",
       "      <td>37.610194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>-119.355004</td>\n",
       "      <td>47.343790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West virginia</th>\n",
       "      <td>-80.683010</td>\n",
       "      <td>38.781910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>-89.895524</td>\n",
       "      <td>44.194575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>-105.869493</td>\n",
       "      <td>43.210302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                event_longitude  event_latitude\n",
       "state                                          \n",
       "Alabama              -86.794329       33.273120\n",
       "Alaska              -148.691622       62.656039\n",
       "American samoa      -170.606827       -9.855073\n",
       "Arizona             -111.818135       33.593247\n",
       "Arkansas             -92.645165       34.977785\n",
       "...                         ...             ...\n",
       "Virginia             -78.658510       37.610194\n",
       "Washington          -119.355004       47.343790\n",
       "West virginia        -80.683010       38.781910\n",
       "Wisconsin            -89.895524       44.194575\n",
       "Wyoming             -105.869493       43.210302\n",
       "\n",
       "[68 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_lat_mean = df2.groupby('state')['event_longitude','event_latitude'].sum() / df2.groupby('state')['event_longitude','event_latitude'].count()\n",
    "long_lat_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for replacing all values with the mean of their lat,long\n",
    "df2.reset_index(drop=True)\n",
    "df3 = copy.deepcopy(df2)\n",
    "\n",
    "for i in df3.state.unique()[:-1]: \n",
    "    df3.loc[df['state'] == i, 'event_latitude'] = long_lat_mean.loc[i]['event_latitude']\n",
    "    df3.loc[df['state'] == i, 'event_longitude'] = long_lat_mean.loc[i]['event_longitude']\n",
    "    \n",
    "df3 = df3[df3['event_latitude'].notna()]\n",
    "df3 = df3[df3['event_longitude'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = copy.deepcopy(df3)\n",
    "df4['event_longitude'] = pd.to_numeric(df4['event_longitude'])\n",
    "df4['event_latitude'] = pd.to_numeric(df4['event_latitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Επίσης, αντικαθιστούμε τα nan values των στηλών damage_property, damage_crops, deaths και injuries με 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.reset_index(drop=True)\n",
    "df5 = copy.deepcopy(df4)\n",
    "### setting nan values of damage properties to 0.\n",
    "df5['damage_property'] = df5['damage_property'].replace(np.nan, 0)\n",
    "### setting nan values of damage corps to 0.\n",
    "df5['damage_crops'] = df5['damage_crops'].replace(np.nan, 0)\n",
    "### setting nan values of deaths to 0.\n",
    "df5['deaths'] = df5['deaths'].replace(np.nan, 0)   \n",
    "### setting nan values of injuries to 0.\n",
    "df5['injuries'] = df5['injuries'].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Όπως είδαμε, εκτός απο γεωγραφικά δεδομένα, έχουμε και χρονικά δεδομένα. Επομένως, τα στατιστικά τα οποία αναφέρονται σε USD(us dollars) πρέπει να μετατραπούν ανάλογα με τον πληθωρισμό.\n",
    "\n",
    "Κατεβάσαμε, επομένως, το dataset για το [CPI(Consumer Price Index)](https://fred.stlouisfed.org/series/CPIAUCSL). Μια μεθοδολογία για το πως μετατρέπουμε τις τιμές βάσει της χρονολογίας που θέλουμε βρίσκεται [εδώ]((https://www.rba.gov.au/education/resources/explainers/inflation-and-its-measurement.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Φορτώνουμε το αρχείο με τα δεδομένα για τον πληθωρισμό και στη συνέχεια δημιουργούμε μια νέα στήλη με τον πολλαπλασιαστή για κάθε χρονιά. Στη δική μας περίπτωση μετατρέπουμε τα δεδομένα μας με βάση το 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load inflation data\n",
    "inflation = pd.read_csv('inflation_data.csv')\n",
    "# create index multiplier\n",
    "inflation['CPI_Multiplier'] = inflation['CPI'].iloc[-1] / inflation['CPI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μετατρέπουμε τη στήλη DATE η οποία έχει αναλυτικά της ημερομηνίες(1994-12-1) και κρατάμε μόνο τη χρονιά(1994). Στη συνέχεια, κρατάω τις χρονιές από το 1950 και μετά, καθώς αυτές μας ενδιαφέρουν. Τέλος, βρίσκω το μέσο όρο για κάθε χρονιά και αυτή η τιμή θα αντιπροσωπεύει το CPI MULTIPLIER για τη χρονιά εκείνη(καθώς τα δεδομένα μας έχουν για κάθε μέρα ξεχωριστά και εμείς θα το προσεγγίσουμε ανά χρονιά)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflation ['DATE'] = inflation ['DATE'].apply(lambda x: int(x.split('-')[0]))\n",
    "inflation = inflation[inflation['DATE'] >=1950]\n",
    "del inflation['CPI']\n",
    "my_inflation = inflation.groupby('DATE').sum() / inflation.groupby('DATE').count()\n",
    "\n",
    "# creating a DATE column same as inflation on our storm dataset so that i can\n",
    "# relate inflation and storm dataset\n",
    "df5.reset_index(drop=True)\n",
    "df6 = copy.deepcopy(df5)\n",
    "df6['DATE'] = df6['event_begin_time'].apply(lambda x: x.split('-')[0])\n",
    "df6['DATE'] = df6['DATE'].apply(lambda x: int(x))\n",
    "\n",
    "# fix inflation with base 2019\n",
    "for i in df6.DATE.unique():\n",
    "    df6.loc[df6['DATE'] == i,['damage_property']] *= my_inflation.loc[i].values[0]\n",
    "    df6.loc[df6['DATE'] == i,['damage_crops']] *= my_inflation.loc[i].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Επιπλέον, είδαμε τις εξής πληροφορίες για τις στήλες 'Magnitude', 'Magnitude type' και 'tor_f_scale':\n",
    "\n",
    "'Magnitude' : only used for wind speeds and hail size \n",
    "              Wind speeds are in MPH; Hail sizes are in inches\n",
    "\n",
    "'Magnitude type' : Differentiates between the type of mangitude measured. No magnitude type included for hail.\n",
    "- EG = Wind Estimated Gust \n",
    "- ES = Estimated Sustained Wind  \n",
    "- MS = Measured Sustained Wind  \n",
    "- MG = Measured Wind Gust \n",
    "\n",
    "'tor_f_scale': \"Enhanced Fujita Scale\" describes the strength of the tornado based on the amount and type of damage caused by the tornado. The F-scale of damage will vary in the destruction area; therefore, the highest value of the F-scale is recorded for each event.   \n",
    "- EF0 – Light Damage (40 – 72 mph)  \n",
    "- EF1 – Moderate Damage (73 – 112 mph)  \n",
    "- EF2 – Significant damage (113 – 157 mph)\n",
    "- EF3 – Severe Damage (158 – 206 mph)  \n",
    "- EF4 – Devastating Damage (207 – 260 mph)  \n",
    "- EF5 – Incredible Damage (261 – 318 mph)\n",
    "\n",
    "Επίσης, η τιμή 'EFU' που θα δούμε ότι υπάρχει είναι αντίστοιχο του 'unknown'.\n",
    "https://en.wikipedia.org/wiki/Enhanced_Fujita_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['tor_f_scale'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Βλέπουμε ότι το χαρακτηριστικό tor_f_scale παρουσιάζει και αυτό μια ασυνέπεια στα δεδομένα του. Αυτό, γιατί θα έπρεπε να αποτελείται από τις τιμές EF0,EF1...EF5 αλλά υπάρχουν και τιμές F0,F1..,F5. Επομένως τα μετατρέπουμε όλα στην ίδια τιμή."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inconsistency των δεδομένων και αντίστοιχες διορθώσεις\n",
    "\n",
    "df6['tor_f_scale'].replace('F0', 'EF0', inplace=True)\n",
    "df6['tor_f_scale'].replace('F1', 'EF1', inplace=True)\n",
    "df6['tor_f_scale'].replace('F2', 'EF2',inplace=True)\n",
    "df6['tor_f_scale'].replace('F3', 'EF3',inplace=True)\n",
    "df6['tor_f_scale'].replace('F4', 'EF4',inplace=True)\n",
    "df6['tor_f_scale'].replace('F5', 'EF5',inplace=True)\n",
    "df6['tor_f_scale'].replace('F6', 'EF6',inplace=True)\n",
    "df6['tor_f_scale'].replace('EFU', 'NaN',inplace=True)\n",
    "df6['tor_f_scale'].fillna('NaN',inplace=True)\n",
    "\n",
    "df6['tor_f_scale'].replace('EF0', 0, inplace=True)\n",
    "df6['tor_f_scale'].replace('EF1', 1, inplace=True)\n",
    "df6['tor_f_scale'].replace('EF2', 2, inplace=True)\n",
    "df6['tor_f_scale'].replace('EF3', 3, inplace=True)\n",
    "df6['tor_f_scale'].replace('EF4', 4, inplace=True)\n",
    "df6['tor_f_scale'].replace('EF5', 5, inplace=True)\n",
    "\n",
    "df6['tor_f_scale'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# διορθώνουμε το index\n",
    "df6.reset_index(drop=True)\n",
    "df7 = copy.deepcopy(df6)\n",
    "df7['index'] = np.arange(len(df7))\n",
    "df7.set_index('index', inplace=True)\n",
    "print('columns:\\n')\n",
    "for i in df7.columns: print(i)\n",
    "print('\\n')\n",
    "print('Dataframe after preprocessing:\\n')\n",
    "df7.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.to_csv(r'preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
